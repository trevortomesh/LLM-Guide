# ChatGPT and Academia -- A Working Guide

<img src="https://upload.wikimedia.org/wikipedia/commons/0/04/ChatGPT_logo.svg" height = "200px">
<p>
Authors: Dr. Trevor M. Tomesh and ChatGPT <br>
Contact: trevor.tomesh@uwrf.edu <br>
Date: May 20th 2023 <br>
Modified: May 21st 2023 <br>
</p>

The arrival of large language models (LLM's) such as ChatGPT, Google Bard, and Microsoft Bing AI (among others) has brought with it
many new opportunities as well as challenges. Of particular concern in academia is the use (and abuse) of LLM's to generate solutions to
homework problems. LLM's are capable of generating convincing solutions that may pass initial scrutiny. 

It must be acknowledged that, in spite of the obvious academic integrity challenges that LLM's present, they may also be used to enhance
teaching and learning outcomes. 

As such, I encourage you to experiment and learn from LLM's so long as these tools do not become obstacles in the way of your learning
outcomes. 

## Dr. T's LLM Policy:
As my student you *are permitted* to use an LLM (such as ChatGPT) with the following restrictions:
- Unless otherwise indicated, you must not use an LLM on quizzes or exams.
- You must properly cite the use of an LLM (see sections 2 and 3 of the LLM Guide).
- Your grade will reflect the amount (and quality) of original work you have put in. Even if you've cited your source(s) adequately
if you turn in an assignment that was completely LLM generated, **you will receive a zero**.
- All submissions are subject (at my discretion) to scrutiny for evidence of LLM usage, even submissions that do not acknowledge
the use of an LLM. 
- LLM use in violation of this policy is subject to academic penalty measures consistent with the UW system policy on plagiarism.

In order to uphold the high academic integrity standards expected of a student at the University of Wisconsin-River Falls, you should 
familiarize yourself with the following guidelines pertaining to the use of LLM's:

## 1) Be honest. 
The fundamental issue underlying most academic misconduct is dishonesty. Copying work from another student, commissioning
another person to write a paper, and using an LLM to complete work without proper attribution are examples of dishonest behavior. The understanding
when one submits an assignment or takes an exam or quiz is that the work being submitted has been done by the submitter unless noted otherwise. 
Without proper acknowledgment that this is not the case, a misrepresentation of the truth has been committed, and therefore academic misconduct has
been committed. If an LLM is used to any significant degree to complete a homework assignment, it should be acknowledged how the LLM was used, why it was used, and where it was used.

## 2) Give credit.
As with any source of knowledge that does not directly come from the author of a given piece, LLM's should be given credit as a source of knowledge. You may cite LLM's such as ChatGPT like so:


> Author: OpenAI Year: [Year of the generated response] Title of the response: [Title of the response] Source: ChatGPT (Version [version number]). Retrieved from [URL]


Here's an example of how the citation would look:


> OpenAI. (2023). Citing ChatGPT. ChatGPT (Version 4). Retrieved from *https://chat.openai.com*


## 3) **Describe what, how and why, and where.** 
There are several different ways that LLM's may be used to help with coursework. ChatGPT is useful to check spelling and grammar. It may also be used to debug code with stubborn issues. Maybe it is used to write an algorithm. However an LLM is used, it must be stated clearly *what* it was used for, *how* it was used and *why* it was used and *where* it was used. This may simply mean including a footnote at the end of a submission stating something to the effect of: 

>I would like to acknowledge the use of ChatGPT for the purposes of correction of grammar and spelling errors as well as suggestions for stylistic improvements. 

For more specific usages of an LLM -- for example, in the creation of a specific algorithm or a block of text, the citation syntax listed in point 2 should be used in conjunction with an appropriate in-line citation:

> The following algorithm (ChatGPT,2023) was used to calculate the cluster boundaries for our set of data.

Followed by the appropriate citation in the references:


> <center><b>REFERENCES</b></center>
> OpenAI. (2023, May 23). *Conversation with ChatGPT: Python Algorithm for Finding Clusters of Data*. 
> chat.openai.com. chat.openai.com

## 4) Understanding First
The entire purpose of a university education is to learn *how to think*. Therefore, to appropriately use a tool like ChatGPT, it is critical that you first seek to understand the concepts behind the solutions. LLM's are useful for giving detailed explanations and may be used not only to generate solutions but to aid in the understanding of these solutions. This may take a little prompt engineering. For example, you might simply ask ChatGPT the following:

> Write me an algorithm in Python that finds clusters of data.

To which it will respond with just a code listing. However, if you want to understand how the algorithm works, you might try this prompt:

> Write me an algorithm in Python that finds clusters of data. Explain the program step-by-step like a tutor so I can understand the fundamental concepts behind the algorithm.

This will give you a detailed explanation of the algorithm. You can always ask follow-up questions if you are still unsure.

In summary: seek understanding first, then proceed with implementation. 

## 5) Don't trust the robots!
Large Language Models are just that -- models. In the legendary words of George E. P. Box -- [“All models are wrong, but some are useful”.](https://www.lacan.upc.edu/admoreWeb/2018/05/all-models-are-wrong-but-some-are-useful-george-e-p-box/#:~:text=“All%20models%20are%20wrong%2C%20but%20some%20are%20useful”%20is,British%20statistician%20George%20E.%20P.%20Box.)
LLM's like ChatGPT are not intelligent beings. They do not "think". They do not have a conscience or consciousness. LLM's are merely mimicking human language while simultaneously pulling information from a massive set of data. As such LLM's can be -- and frequently are -- incorrect. You should *always* use your own judgment when dealing with the output of an LLM. Furthermore, you should not trust the output of an LLM to be unbiased. The quality of models is only as good as the data upon which they are trained. 

## 6) Keep receipts.
There may come a time when you are asked to prove that you've used an LLM in the way you've claimed. There may also come a time when you are asked what prompt you used to produce a solution. You should, therefore, always keep a record of the conversations you have had with your LLM. You should always store your LLM chats somewhere with long-term storage as these chats are usually only retained for a limited time. ChatGPT (as of this writing) claims to only retain logs for 30 days. Better yet, you may be able to attach your relevant chat logs as an appendix to your work!

## 7) Don't assume permission.
Each instructor will have a different philosophy and policy on the appropriate use of LLM's. **You should never assume that other instructors are happy for you to use ChatGPT** or that they are even aware of its capabilities. It is best to assume that its use is 
prohibited unless informed otherwise. Furthermore, *if you are unsure, ask!*

## In Summary
*Note: The following summary was entirely written by ChatGPT (OpenAI, 2023)*

In conclusion, the use of large language models (LLMs) like ChatGPT in academia presents both opportunities and challenges. While LLMs can enhance teaching and learning outcomes, they also raise concerns about academic integrity when used to generate solutions to homework problems. To maintain academic integrity standards, it is important to be honest and give credit when using LLMs.

Students should clearly state how and why they used LLMs, providing appropriate citations and acknowledgments. When using LLMs for tasks like checking spelling and grammar or debugging code, a general acknowledgment in the submission may be sufficient. However, for specific usages like algorithm creation, in-line citations and references should be included.

Understanding the concepts behind the solutions is crucial, as the purpose of education is to learn how to think. LLMs can provide detailed explanations, but seeking understanding first and then implementing the solutions is recommended. Students should not solely rely on LLMs and should exercise their own judgment as models can be incorrect and biased.

Keeping records of conversations with LLMs is important for future reference or verification purposes. It is also crucial to be aware that different instructors may have different policies regarding the use of LLMs, so students should never assume permission and should inquire about their instructor's stance.

By adhering to these guidelines, students can navigate the use of LLMs in academia while upholding academic integrity and maximizing the benefits of these tools for their learning outcomes.



## Todo's for this guide:

- [ ] include discussion on prompt engineering. 


## References

OpenAI. (2023, May 21). "ChatGPT and Academia -- A Working Guide" [Chat conversation]. *chat.openai.com*
